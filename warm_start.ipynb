{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], os.pardir, os.pardir))\n",
    "from utils import SimpleProblem\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import Model, GRB, QuadExpr, LinExpr\n",
    "\n",
    "from utils import build_gurobi_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNSolver_eq_proj(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=200, bias=True)\n",
       "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (5): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=200, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_utils import NNSolver_eq_proj\n",
    "\n",
    "filepath = \"/home/jxxiong/A-xjx/DC3/datasets/simple/random_simple_dataset_var200_ineq100_eq100_ex10000\"\n",
    "with open(filepath, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "arg_path = \"/home/jxxiong/A-xjx/DC3/results/SimpleProblem-200-100-100-10000/method_eq_proj/6e159980feacc6482172a8c3a901f63bc1ce625e/1712566930-9855366/args.dict\"\n",
    "args = pickle.load(open(arg_path, 'rb'))\n",
    "\n",
    "model = NNSolver_eq_proj(data, args)\n",
    "\n",
    "model_path = \"/home/jxxiong/A-xjx/DC3/results/SimpleProblem-200-100-100-10000/method_eq_proj/6e159980feacc6482172a8c3a901f63bc1ce625e/1712566930-9855366/solver_net.dict\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "# model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "for attr in dir(data):\n",
    "    var = getattr(data, attr)\n",
    "    if not callable(var) and not attr.startswith(\"__\") and torch.is_tensor(var):\n",
    "        try:\n",
    "            setattr(data, attr, var.to(DEVICE))\n",
    "        except AttributeError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = data.A\n",
    "G = data.G\n",
    "h = data.h\n",
    "Q = data.Q\n",
    "p = data.p\n",
    "\n",
    "A_np = data.A_np\n",
    "G_np = data.G_np\n",
    "h_np = data.h_np\n",
    "Q_np = data.Q_np\n",
    "p_np = data.p_np\n",
    "\n",
    "X = data.X\n",
    "X_np = data.X_np\n",
    "\n",
    "num_var = A.shape[1]\n",
    "num_eq = A.shape[0]\n",
    "num_ineq = G.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter OutputFlag to value 1\n",
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (linux64 - \"Ubuntu 22.04.2 LTS\")\n",
      "\n",
      "CPU model: 12th Gen Intel(R) Core(TM) i9-12900K, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 24 physical cores, 24 logical processors, using up to 24 threads\n",
      "\n",
      "Optimize a model with 200 rows, 200 columns and 40000 nonzeros\n",
      "Model fingerprint: 0xae740817\n",
      "Model has 200 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [7e-06, 4e+00]\n",
      "  Objective range  [2e-03, 1e+00]\n",
      "  QObjective range [1e-02, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e-02, 1e+01]\n",
      "Presolve time: 0.01s\n",
      "Presolved: 200 rows, 200 columns, 40000 nonzeros\n",
      "Presolved model has 200 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " Free vars  : 200\n",
      " AA' NZ     : 1.990e+04\n",
      " Factor NZ  : 2.010e+04\n",
      " Factor Ops : 2.687e+06 (less than 1 second per iteration)\n",
      " Threads    : 24\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0  -1.41304913e-01 -6.63109554e-02  6.66e-16 7.31e+00  1.00e+06     0s\n",
      "   1   2.39100460e+06 -2.40895128e+06  2.58e+01 1.07e+02  1.91e+05     0s\n",
      "   2   6.86835014e+05 -6.96489528e+05  2.95e-12 7.93e-07  2.77e+04     0s\n",
      "   3   9.94853385e+04 -1.03175069e+05  2.33e-12 1.83e-12  4.05e+03     0s\n",
      "   4   1.41366286e+04 -1.55437736e+04  7.99e-13 4.09e-13  5.94e+02     0s\n",
      "   5   1.90102797e+03 -2.43612214e+03  3.45e-13 2.05e-13  8.67e+01     0s\n",
      "   6   2.09437047e+02 -4.14999305e+02  1.01e-13 2.40e-14  1.25e+01     0s\n",
      "   7  -3.70660509e+00 -8.56487420e+01  3.97e-14 1.25e-14  1.64e+00     0s\n",
      "   8  -2.57412956e+01 -3.97742947e+01  1.23e-14 8.47e-15  2.81e-01     0s\n",
      "   9  -2.88374010e+01 -3.03187542e+01  4.47e-15 6.98e-15  2.96e-02     0s\n",
      "  10  -2.91817432e+01 -2.92376643e+01  2.86e-15 5.22e-15  1.12e-03     0s\n",
      "  11  -2.91992622e+01 -2.92016316e+01  2.05e-15 6.85e-15  4.74e-05     0s\n",
      "  12  -2.92000126e+01 -2.92001667e+01  1.67e-15 7.13e-15  3.08e-06     0s\n",
      "  13  -2.92000503e+01 -2.92000635e+01  2.07e-15 3.77e-15  2.65e-07     0s\n",
      "  14  -2.92000515e+01 -2.92000520e+01  2.69e-15 6.27e-15  8.62e-09     0s\n",
      "  15  -2.92000515e+01 -2.92000515e+01  2.97e-15 7.27e-15  8.57e-12     0s\n",
      "\n",
      "Barrier solved model in 15 iterations and 0.05 seconds (0.04 work units)\n",
      "Optimal objective -2.92000515e+01\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[67, 69, 73, 83, 84, 87, 93, 96, 98, 102, 107, 116, 134, 136, 141, 142, 144]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model = build_gurobi_model(Q_np, p_np, A_np, X_np[idx], G_np, h_np)\n",
    "full_model.setParam('OutputFlag', 1)\n",
    "full_model.optimize()\n",
    "optimal_val_full = full_model.objVal\n",
    "time_full = full_model.Runtime\n",
    "optimal_x_full = np.array([v.x for v in full_model.getVars()])\n",
    "duals_full = np.array([c.Pi for c in full_model.getConstrs()])\n",
    "duals_ineq_target = duals_full[-G.shape[0]:]\n",
    "duals_eq_target = duals_full[:A.shape[0]]\n",
    "active_ineq_target = np.where(np.abs(G_np@optimal_x_full - h_np) <= 1e-4)[0]\n",
    "active_ineq_target.tolist()\n",
    "active_ineq_index_target = [50 + x for x in active_ineq_target]\n",
    "active_ineq_index_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove part of the inequality constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m Yhat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m Ystar \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mprojection(X[idx]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m), Yhat)\n\u001b[1;32m      4\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.conda/envs/scopf/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/A-xjx/DC3/model_utils.py:34\u001b[0m, in \u001b[0;36mNNSolver_eq_proj.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m prob_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobType\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prob_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m prob_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonconvex\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(x)\n",
      "File \u001b[0;32m~/.conda/envs/scopf/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/scopf/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/scopf/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/scopf/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "Yhat = model(X[idx].unsqueeze(0).to('cuda'))\n",
    "Ystar = data.projection(X[idx].unsqueeze(0).to('cuda'), Yhat)\n",
    "end_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/scopf/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/A-xjx/DC3/model_utils.py:34\u001b[0m, in \u001b[0;36mNNSolver_eq_proj.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m prob_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobType\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prob_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m prob_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonconvex\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(x)\n",
      "File \u001b[0;32m~/.conda/envs/scopf/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/scopf/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/scopf/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/scopf/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Yhat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Yhat' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time:  0.12717771530151367\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Ystar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m inference_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference time: \u001b[39m\u001b[38;5;124m\"\u001b[39m, inference_time)\n\u001b[0;32m----> 7\u001b[0m Ystar \u001b[38;5;241m=\u001b[39m \u001b[43mYstar\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      8\u001b[0m ineq_sorted_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mG_np\u001b[38;5;129m@Ystar\u001b[39m \u001b[38;5;241m+\u001b[39m h_np)\n\u001b[1;32m      9\u001b[0m ineq_sorted \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;241m-\u001b[39mG_np\u001b[38;5;129m@Ystar\u001b[39m \u001b[38;5;241m+\u001b[39m h_np)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ystar' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%time Yhat = model(X[idx].unsqueeze(0))\n",
    "%time Ystar = data.projection(X[idx].unsqueeze(0), Yhat)\n",
    "end_time = time.time()\n",
    "inference_time = end_time - start_time\n",
    "print(\"Inference time: \", inference_time)\n",
    "Ystar = Ystar.detach().numpy().flatten()\n",
    "ineq_sorted_index = np.argsort(-G_np@Ystar + h_np)\n",
    "ineq_sorted = np.sort(-G_np@Ystar + h_np)\n",
    "print(ineq_sorted)\n",
    "print(ineq_sorted_index)\n",
    "inactive_ineq_index = ineq_sorted_index[ineq_sorted > 2]\n",
    "print(inactive_ineq_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(inactive_ineq_index).intersection(set(active_ineq_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(np.arange(num_ineq), active_ineq_target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter OutputFlag to value 1\n",
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (linux64 - \"Ubuntu 22.04.2 LTS\")\n",
      "\n",
      "CPU model: 12th Gen Intel(R) Core(TM) i9-12900K, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 24 physical cores, 24 logical processors, using up to 24 threads\n",
      "\n",
      "Optimize a model with 122 rows, 200 columns and 24400 nonzeros\n",
      "Model fingerprint: 0xc764a257\n",
      "Model has 200 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [7e-06, 4e+00]\n",
      "  Objective range  [2e-03, 1e+00]\n",
      "  QObjective range [1e-02, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e-02, 9e+00]\n",
      "Presolve time: 0.01s\n",
      "Presolved: 122 rows, 200 columns, 24400 nonzeros\n",
      "Presolved model has 200 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " Free vars  : 200\n",
      " AA' NZ     : 7.381e+03\n",
      " Factor NZ  : 7.503e+03\n",
      " Factor Ops : 6.127e+05 (less than 1 second per iteration)\n",
      " Threads    : 24\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0  -1.41318098e-01 -6.63111202e-02  5.83e-16 7.31e+00  1.00e+06     0s\n",
      "   1   6.94170820e+05 -6.90151793e+05  2.57e-12 7.31e-06  1.26e+05     0s\n",
      "   2   1.02156822e+05 -1.00663456e+05  9.83e-13 7.54e-12  1.84e+04     0s\n",
      "   3   1.51204417e+04 -1.45932261e+04  4.95e-13 1.33e-13  2.70e+03     0s\n",
      "   4   2.25457301e+03 -2.09679638e+03  2.20e-13 5.51e-14  3.96e+02     0s\n",
      "   5   3.26200607e+02 -3.09314304e+02  1.03e-13 3.76e-14  5.78e+01     0s\n",
      "   6   2.76614802e+01 -6.35851761e+01  3.11e-14 1.11e-14  8.30e+00     0s\n",
      "   7  -2.09339486e+01 -3.29358595e+01  1.06e-14 6.22e-15  1.09e+00     0s\n",
      "   8  -2.83371626e+01 -2.95291317e+01  2.93e-15 3.39e-15  1.08e-01     0s\n",
      "   9  -2.91195362e+01 -2.92343063e+01  2.11e-15 4.40e-15  1.04e-02     0s\n",
      "  10  -2.91950364e+01 -2.92045813e+01  2.08e-15 5.38e-15  8.68e-04     0s\n",
      "  11  -2.91998094e+01 -2.92005551e+01  2.16e-15 5.11e-15  6.78e-05     0s\n",
      "  12  -2.92000409e+01 -2.92000909e+01  1.86e-15 8.74e-15  4.55e-06     0s\n",
      "  13  -2.92000512e+01 -2.92000553e+01  3.52e-15 5.77e-15  3.75e-07     0s\n",
      "  14  -2.92000515e+01 -2.92000516e+01  1.97e-15 7.27e-15  2.47e-09     0s\n",
      "\n",
      "Barrier solved model in 14 iterations and 0.06 seconds (0.03 work units)\n",
      "Optimal objective -2.92000515e+01\n",
      "\n",
      "Value: full=-29.20005153648649, reduced=-29.20005153597883, diff=-5.076614684185188e-10\n",
      "Time: full=0.07189488410949707, reduced=0.06112980842590332, diff=0.01076507568359375\n"
     ]
    }
   ],
   "source": [
    "remaining_ineq_index = np.setdiff1d(np.arange(num_ineq), inactive_ineq_index)\n",
    "# remaining_ineq_index = active_ineq_target[60:]\n",
    "\n",
    "\n",
    "G_remaining = G[remaining_ineq_index]\n",
    "h_remaining = h[remaining_ineq_index]\n",
    "model_reduced = build_gurobi_model(Q, p, A, X_np[idx], G_remaining, h_remaining)\n",
    "model_reduced.setParam('OutputFlag', 1)\n",
    "# initialize the primal variables in model_hat2\n",
    "# for i, v in enumerate(model_hat2.getVars()):\n",
    "#     v.setAttr('Start', Ystar[i])\n",
    "model_reduced.optimize()\n",
    "optimal_val = model_reduced.objVal\n",
    "time_reduced = model_reduced.Runtime + inference_time\n",
    "optimal_x = np.array([v.x for v in model_reduced.getVars()])\n",
    "print(\"Value: full={}, reduced={}, diff={}\".format(optimal_val_full, optimal_val, optimal_val_full - optimal_val))\n",
    "print(\"Time: full={}, reduced={}, diff={}\".format(time_full, time_reduced, time_full - time_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# osqp warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004205560684204102\n",
      "-29.200070154743347\n"
     ]
    }
   ],
   "source": [
    "from utils import build_osqp\n",
    "\n",
    "num_trial = 10\n",
    "\n",
    "total_time = 0.0\n",
    "for _ in range(num_trial):\n",
    "    solver = build_osqp(Q_np, p_np, A_np, X_np[idx], G_np, h_np)\n",
    "    # solver1.warm_start(x=Ystar)\n",
    "    start_time = time.time()\n",
    "    results = solver.solve()\n",
    "    end_time = time.time()\n",
    "    total_time += (end_time - start_time)\n",
    "print(total_time / num_trial)\n",
    "print(results.info.obj_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004297995567321777\n",
      "-29.200039984137756\n"
     ]
    }
   ],
   "source": [
    "total_time_ws = 0.0\n",
    "for _ in range(num_trial):\n",
    "    solver_ws = build_osqp(Q_np, p_np, A_np, X_np[idx], G_np, h_np)\n",
    "    solver_ws.warm_start(x=Ystar)\n",
    "    start_time = time.time()\n",
    "    result_ws = solver_ws.solve()\n",
    "    end_time = time.time()\n",
    "    total_time_ws += (end_time - start_time)\n",
    "print(total_time_ws / num_trial + inference_time)\n",
    "print(result_ws.info.obj_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0023162126541137694\n",
      "-29.200051564649282\n"
     ]
    }
   ],
   "source": [
    "total_time_reduced = 0.0\n",
    "for _ in range(num_trial):\n",
    "    solver_reduced = build_osqp(Q_np, p_np, A_np, X_np[idx], G_remaining, h_remaining)\n",
    "    start_time = time.time()\n",
    "    results_reduced = solver_reduced.solve()\n",
    "    end_time = time.time()\n",
    "    total_time_reduced = end_time - start_time\n",
    "print(total_time_reduced / num_trial + inference_time)\n",
    "print(results_reduced.info.obj_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0022213935852050783\n",
      "-29.200125160105603\n"
     ]
    }
   ],
   "source": [
    "total_time_reduced_ws = 0.0\n",
    "for _ in range(num_trial):\n",
    "    solver_reduced_ws = build_osqp(Q_np, p_np, A_np, X_np[idx], G_remaining, h_remaining)\n",
    "    solver_reduced_ws.warm_start(x=Ystar)\n",
    "    start_time = time.time()\n",
    "    results_reduced_ws = solver_reduced_ws.solve()\n",
    "    end_time = time.time()\n",
    "    total_time_reduced_ws = end_time - start_time\n",
    "print(total_time_reduced_ws / num_trial + inference_time)\n",
    "print(results_reduced_ws.info.obj_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "for i in range(9300, 10000):\n",
    "    full_model = build_gurobi_model(Q_np, p_np, A_np, X_np[idx], G_np, h_np)\n",
    "    full_model.optimize()\n",
    "    optimal_x_full = np.array([v.x for v in full_model.getVars()])\n",
    "    active_ineq_target = np.where(np.abs(G_np@optimal_x_full - h_np) <= 1e-4)[0]\n",
    "    active_ineq_target.tolist()\n",
    "\n",
    "    Yhat = model(X[idx].unsqueeze(0))\n",
    "    Ystar = data.projection(X[idx].unsqueeze(0), Yhat)\n",
    "    Ystar = Ystar.detach().numpy().flatten()\n",
    "    ineq_sorted_index = np.argsort(-G_np@Ystar + h_np)\n",
    "    ineq_sorted = np.sort(-G_np@Ystar + h_np)\n",
    "    inactive_ineq_index = ineq_sorted_index[ineq_sorted > 2]\n",
    "\n",
    "    error.append(len(set(inactive_ineq_index).intersection(set(active_ineq_target))))\n",
    "print(max(error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scopf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
